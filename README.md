
# Naive Bayes Classifier from Scratch ðŸŽ¯

This project demonstrates a manual implementation of the **Naive Bayes classification algorithm** using Python and Pandas on the classic **Play Tennis** dataset.

ðŸ” The goal is to predict whether to play tennis based on weather conditions like `outlook`, `temperature`, `humidity`, and `wind`.

---

## ðŸ“ Dataset

The dataset used (`play_tennis.csv`) includes 14 instances with the following columns:
- `day`
- `outlook`
- `temperature`
- `humidity`
- `wind`
- `play` (Target: yes/no)

We drop the `day` column as it is irrelevant for prediction.

---

## ðŸ§  What I Did

- Calculated **prior probabilities**:  
  \[
  P(yes) = 9/14, P(no) =5/14
  \]

- Used `pd.crosstab()` to manually compute **conditional probabilities** for each feature value.

- Applied Naive Bayes formula to predict the class for a test query:  
  `{outlook=sunny, temperature=hot, humidity=high, wind=weak}`

- Compared \( P({yes}|{features}) \) and \( P({no}|{features}) \) to make a final prediction.

---

## ðŸ“š Learning Outcome

âœ… Understood how Naive Bayes works under the hood  
âœ… Learned how to calculate priors and conditionals manually  
âœ… Applied probability theory to real classification problems  
âœ… Gained confidence in implementing ML logic from scratch

---

## ðŸš€ Future Improvements

- Extend it to use `sklearn` for comparison  
- Visualize decision boundaries (for numeric datasets)  
- Add Laplace smoothing  
- Test on new datasets (e.g., Iris, Titanic, SMS spam)

---

## ðŸ’» Tech Stack

- Python
- Pandas
- NumPy
- Google Colab 

---

## ðŸ“¸ Sample Output

Test Query: {'outlook': 'sunny', 'temperature': 'hot', 'humidity': 'high', 'wind': 'weak'}

P(Yes | features):  0.010582010582010581
P(No | features):   0.02742857142857143

Prediction: âŒ No (Donâ€™t Play Tennis)

---

## ðŸ§‘â€ðŸ« Credits

> This implementation was based on a tutorial by [CampusX](https://youtu.be/DeeWsqoY4Eo?si=_gZQeJ0Wsz8qloWL).  
> I recreated the logic myself as part of my learning process.

---
